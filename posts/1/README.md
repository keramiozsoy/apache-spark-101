# Post 1

## What is Apache Spark

Apache Spark is, unified analytics engine for big data, a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.


Apache Spark is used variety of software developers. It has been written with Scala Programming Language.  But it is not mandatory to use Scala. 
There are another APIs for software developers.

- Scala (https://spark.apache.org/docs/latest/api/scala/org/apache/spark/index.html)

- .NET  ( https://github.com/dotnet/spark )

- Java (https://spark.apache.org/docs/latest/api/java/index.html)

- Python ( https://spark.apache.org/docs/latest/api/python/index.html)

- R ( https://spark.apache.org/docs/latest/api/R/index.html )

- SQL ( https://spark.apache.org/docs/latest/api/sql/index.html ) 


If you're curious, you can visit the frequently asked questions page by clicking the link below.

- https://spark.apache.org/faq.html